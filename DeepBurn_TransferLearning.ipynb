{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Burn Wound Classification by Transfer Learning\n",
    "\n",
    "by Carsten Isert, Nov. 2017\n",
    "\n",
    "This notebook is originally based on the dog-breed classification notebook from the Udacity AI Nanodegree.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "The goal of this first step is to classify the burn degree on a given image.\n",
    "\n",
    "There are two stages that will be covered in this notebook.\n",
    "\n",
    "First, given an input image, the network will output the best matching class from the following list:\n",
    "\n",
    "1. First degree: Superficial burns (S)\n",
    "2. Second degree: Partial thickness burns (PT)\n",
    "3. Third degree: Full thickness burns (FT)\n",
    "4. No burn detected in image (this applies to all pre-trained ImageNet pictures)\n",
    "\n",
    "Second, given an input image, the softmax will output the percentage of each of the 4 categories mentioned above as the area of skin that is related to the specific class in the given picture. The background is not considered.\n",
    "\n",
    "\n",
    "![Sample Burn Image](data/train/02_SecondDegree/foot_004.jpg)\n",
    "\n",
    "We break the notebook into separate steps.  Feel free to use the links below to navigate the notebook.\n",
    "\n",
    "* [Step 0](#step0): Import Datasets\n",
    "* [Step 1](#step1): Use a CNN to Classify Burn Wounds (using Transfer Learning)\n",
    "* [Step 2](#step2): Output percentage of skin burned with respective class\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## Step 0: Import Dataset\n",
    "\n",
    "### Import \n",
    "\n",
    "In the code cell below, we import a dataset of burn images.  We populate a few variables through the use of the `load_files` function from the scikit-learn library:\n",
    "- `train_files`, `valid_files`, `test_files` - numpy arrays containing file paths to images\n",
    "- `train_targets`, `valid_targets`, `test_targets` - numpy arrays containing onehot-encoded classification labels \n",
    "- `burn_classes` - list of string-valued burn classifications for translating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 total categories.\n",
      "['data/train/01_FirstDegree/', 'data/train/02_SecondDegree/', 'data/train/03_ThirdDegree/', 'data/train/04_Regular/']\n",
      "There are 93 total burn images.\n",
      "\n",
      "There are 79 training images.\n",
      "There are 7 validation images.\n",
      "There are 7 test images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np_utils.to_categorical(np.array(data['target']), 4)\n",
    "    return files, targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('data/train')\n",
    "valid_files, valid_targets = load_dataset('data/valid')\n",
    "test_files, test_targets = load_dataset('data/test')\n",
    "\n",
    "# get the burn classes\n",
    "# We only take the characters from a starting position to remove the path\n",
    "burn_classes = [item[11:-1] for item in sorted(glob(\"data/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total categories.' % len(burn_classes))\n",
    "print(burn_classes)\n",
    "print('There are %s total burn images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training images.' % len(train_files))\n",
    "print('There are %d validation images.' % len(valid_files))\n",
    "print('There are %d test images.'% len(test_files))\n",
    "\n",
    "for file in train_files: assert('.DS_Store' not in file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/train/03_ThirdDegree/hand_002.jpg'\n",
      " 'data/train/02_SecondDegree/arm_002.png'\n",
      " 'data/train/02_SecondDegree/arm_006.ashx'\n",
      " 'data/train/04_Regular/chest_002.jpeg'\n",
      " 'data/train/03_ThirdDegree/arm_001.jpg'\n",
      " 'data/train/04_Regular/chest_008.jpg'\n",
      " 'data/train/04_Regular/hand_0005.jpg'\n",
      " 'data/train/04_Regular/hand_0008.jpg'\n",
      " 'data/train/03_ThirdDegree/body_001.jpg'\n",
      " 'data/train/04_Regular/arm_004.jpg'\n",
      " 'data/train/02_SecondDegree/hand_006.jpg'\n",
      " 'data/train/04_Regular/chest_001.jpg'\n",
      " 'data/train/01_FirstDegree/arm_003.jpg'\n",
      " 'data/train/04_Regular/hand_0002.jpg' 'data/train/04_Regular/arm_003.jpg'\n",
      " 'data/train/02_SecondDegree/foot_002.jpg'\n",
      " 'data/train/01_FirstDegree/arm_004.jpg'\n",
      " 'data/train/01_FirstDegree/shoulder_001.jpg'\n",
      " 'data/train/01_FirstDegree/back_004.jpg'\n",
      " 'data/train/02_SecondDegree/arm_001.jpg'\n",
      " 'data/train/02_SecondDegree/hand_008.jpg'\n",
      " 'data/train/02_SecondDegree/hand_003.jpg'\n",
      " 'data/train/02_SecondDegree/hand_007.jpg'\n",
      " 'data/train/04_Regular/hand_0010.jpg' 'data/train/04_Regular/arm_001.jpg'\n",
      " 'data/train/01_FirstDegree/hand_004.jpg'\n",
      " 'data/train/04_Regular/arm_006.jpg' 'data/train/04_Regular/arm_009.jpg'\n",
      " 'data/train/01_FirstDegree/back_003.jpeg'\n",
      " 'data/train/04_Regular/arm_002.png' 'data/train/04_Regular/hand_0003.jpg'\n",
      " 'data/train/01_FirstDegree/arm_005.JPG'\n",
      " 'data/train/02_SecondDegree/foot_001.jpg'\n",
      " 'data/train/03_ThirdDegree/hand_005.jpg'\n",
      " 'data/train/02_SecondDegree/arm_003.jpg'\n",
      " 'data/train/01_FirstDegree/chest_003.jpg'\n",
      " 'data/train/03_ThirdDegree/hand_003.jpg'\n",
      " 'data/train/01_FirstDegree/shoulder_002.jpg'\n",
      " 'data/train/01_FirstDegree/chest_001.jpg'\n",
      " 'data/train/02_SecondDegree/back_001.jpg'\n",
      " 'data/train/02_SecondDegree/shoulder_002.jpeg'\n",
      " 'data/train/04_Regular/arm_007.jpg'\n",
      " 'data/train/01_FirstDegree/arm_002.jpg'\n",
      " 'data/train/02_SecondDegree/face_001.jpg'\n",
      " 'data/train/04_Regular/chest_005.jpg'\n",
      " 'data/train/01_FirstDegree/chest_006.jpg'\n",
      " 'data/train/03_ThirdDegree/hand_006.jpg'\n",
      " 'data/train/01_FirstDegree/leg_002.jpg'\n",
      " 'data/train/02_SecondDegree/arm_005.jpg'\n",
      " 'data/train/01_FirstDegree/shoulder_003.jpg'\n",
      " 'data/train/02_SecondDegree/foot_004.jpg'\n",
      " 'data/train/01_FirstDegree/leg_001.png'\n",
      " 'data/train/01_FirstDegree/arm_001.jpg'\n",
      " 'data/train/04_Regular/hand_0009.jpg'\n",
      " 'data/train/01_FirstDegree/hand_002.jpg'\n",
      " 'data/train/01_FirstDegree/back_002.jpg'\n",
      " 'data/train/04_Regular/chest_007.jpeg'\n",
      " 'data/train/01_FirstDegree/hand_003.jpg'\n",
      " 'data/train/03_ThirdDegree/hand_004.jpg'\n",
      " 'data/train/01_FirstDegree/neck_001.jpg'\n",
      " 'data/train/04_Regular/hand_0004.jpg'\n",
      " 'data/train/01_FirstDegree/back_005.jpg'\n",
      " 'data/train/01_FirstDegree/chest_005.jpg'\n",
      " 'data/train/01_FirstDegree/tummy_001.jpg'\n",
      " 'data/train/02_SecondDegree/hand_002.jpg'\n",
      " 'data/train/03_ThirdDegree/arm_003.jpeg'\n",
      " 'data/train/02_SecondDegree/hand_004.jpg'\n",
      " 'data/train/04_Regular/chest_004.gif' 'data/train/04_Regular/arm_005.jpg'\n",
      " 'data/train/01_FirstDegree/chest_004.jpg'\n",
      " 'data/train/04_Regular/hand_0001.jpg'\n",
      " 'data/train/02_SecondDegree/hand_001.jpg'\n",
      " 'data/train/01_FirstDegree/neck_002.jpg'\n",
      " 'data/train/01_FirstDegree/back_006.jpg'\n",
      " 'data/train/04_Regular/hand_0006.jpg'\n",
      " 'data/train/04_Regular/chest_006.jpg'\n",
      " 'data/train/04_Regular/chest_003.jpg'\n",
      " 'data/train/03_ThirdDegree/arm_004.jpeg'\n",
      " 'data/train/02_SecondDegree/shoulder_003.jpg']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "<a id='step1'></a>\n",
    "## Step 1: Convert Dataset and Test Standard Classification with ResNet\n",
    "\n",
    "In this section, we use a pre-trained [ResNet-50](http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006) model to detect the contents of our burn images to get a feeling of what a standard model thinks about these images.\n",
    "\n",
    "Our first line of code downloads the ResNet-50 model, along with weights that have been trained on [ImageNet](http://www.image-net.org/), a very large, very popular dataset used for image classification and other vision tasks.  ImageNet contains over 10 million URLs, each linking to an image containing an object from one of [1000 categories](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a).  Given an image, this pre-trained ResNet-50 model returns a prediction (derived from the available categories in ImageNet) for the object that is contained in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# define ResNet50 model\n",
    "ResNet50_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pre-process the Data\n",
    "\n",
    "When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape\n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, \\text{rows}, \\text{columns}, \\text{channels}),\n",
    "$$\n",
    "\n",
    "where `nb_samples` corresponds to the total number of images (or samples), and `rows`, `columns`, and `channels` correspond to the number of rows, columns, and channels for each image, respectively.  \n",
    "\n",
    "The `path_to_tensor` function below takes a string-valued file path to a color image as input and returns a 4D tensor suitable for supplying to a Keras CNN.  The function first loads the image and resizes it to a square image that is $224 \\times 224$ pixels.  Next, the image is converted to an array, which is then resized to a 4D tensor.  In this case, since we are working with color images, each image has three channels.  Likewise, since we are processing a single image (or sample), the returned tensor will always have shape\n",
    "\n",
    "$$\n",
    "(1, 224, 224, 3).\n",
    "$$\n",
    "\n",
    "The `paths_to_tensor` function takes a numpy array of string-valued image paths as input and returns a 4D tensor with shape \n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, 224, 224, 3).\n",
    "$$\n",
    "\n",
    "Here, `nb_samples` is the number of samples, or number of images, in the supplied array of image paths.  It is best to think of `nb_samples` as the number of 3D tensors (where each 3D tensor corresponds to a different image) in your dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "# Note: modified these two functions, so that we can later also read the inception tensors which \n",
    "# have a different format \n",
    "def path_to_tensor(img_path, width=224, height=224):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(width, height))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (width, heigth, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, width, height, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths, width=224, height=224):\n",
    "    list_of_tensors = [path_to_tensor(img_path, width, height) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Making Predictions with ResNet-50\n",
    "\n",
    "Getting the 4D tensor ready for ResNet-50, and for any other pre-trained model in Keras, requires some additional processing.  First, the RGB image is converted to BGR by reordering the channels.  All pre-trained models have the additional normalization step that the mean pixel (expressed in RGB as $[103.939, 116.779, 123.68]$ and calculated from all pixels in all images in ImageNet) must be subtracted from every pixel in each image.  This is implemented in the imported function `preprocess_input`.  If you're curious, you can check the code for `preprocess_input` [here](https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py).\n",
    "\n",
    "Now that we have a way to format our image for supplying to ResNet-50, we are now ready to use the model to extract the predictions.  This is accomplished with the `predict` method, which returns an array whose $i$-th entry is the model's predicted probability that the image belongs to the $i$-th ImageNet category.  This is implemented in the `ResNet50_predict_labels` function below.\n",
    "\n",
    "By taking the argmax of the predicted probability vector, we obtain an integer corresponding to the model's predicted object class, which we can identify with an object category through the use of this [dictionary](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def ResNet50_predict_labels(img_path):\n",
    "    # returns prediction vector for image located at img_path\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model.predict(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Standard classification\n",
    "\n",
    "As can be seen by the classes produced on a standard ResNet with pre-trained ImageNet weights, the output on the burn images is not giving us a lot of information and we cannot really use this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook, claw\n",
      "lipstick, lip rouge\n",
      "ice lolly, lolly, lollipop, popsicle\n",
      "swimming trunks, bathing trunks\n",
      "sea cucumber, holothurian\n",
      "swimming trunks, bathing trunks\n",
      "Band Aid\n",
      "Band Aid\n",
      "butcher shop, meat market\n",
      "vizsla, Hungarian pointer\n",
      "hippopotamus, hippo, river horse, Hippopotamus amphibius\n",
      "swimming trunks, bathing trunks\n",
      "rotisserie\n",
      "Band Aid\n",
      "punching bag, punch bag, punching ball, punchball\n",
      "sunscreen, sunblock, sun blocker\n",
      "sock\n",
      "sunscreen, sunblock, sun blocker\n",
      "tile roof\n",
      "Band Aid\n",
      "ice lolly, lolly, lollipop, popsicle\n",
      "Band Aid\n",
      "cleaver, meat cleaver, chopper\n",
      "mouse, computer mouse\n",
      "tub, vat\n",
      "mouse, computer mouse\n",
      "bikini, two-piece\n",
      "punching bag, punch bag, punching ball, punchball\n",
      "pomegranate\n",
      "mouse, computer mouse\n"
     ]
    }
   ],
   "source": [
    "# Translation of categories taken from https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a\n",
    "import imagenet1000_dict \n",
    "\n",
    "burn_files_short = train_files[:30]\n",
    "\n",
    "for file in burn_files_short:\n",
    "    prediction_id = ResNet50_predict_labels(file)\n",
    "    prediction_text = imagenet1000_dict.id_to_human[prediction_id]\n",
    "    print(prediction_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helpers for training CNNs taken from \n",
    "# https://github.com/madhavajay/nd889/blob/master/2_deep_learning/1_dog_breed_classifier/dog_app.ipynb\n",
    "# many thanks to Jay for these helper functions\n",
    "\n",
    "import keras\n",
    "import timeit\n",
    "\n",
    "# graph the history of model.fit\n",
    "def show_history_graph(history):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show() \n",
    "\n",
    "# callback to show the total time taken during training and for each epoch\n",
    "class EpochTimer(keras.callbacks.Callback):\n",
    "    train_start = 0\n",
    "    train_end = 0\n",
    "    epoch_start = 0\n",
    "    epoch_end = 0\n",
    "    \n",
    "    def get_time(self):\n",
    "        return timeit.default_timer()\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_start = self.get_time()\n",
    " \n",
    "    def on_train_end(self, logs={}):\n",
    "        self.train_end = self.get_time()\n",
    "        print('Training took {} seconds'.format(self.train_end - self.train_start))\n",
    " \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_start = self.get_time()\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_end = self.get_time()\n",
    "        print('Epoch {} took {} seconds'.format(epoch, self.epoch_end - self.epoch_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data\n",
    "We rescale the images by dividing every pixel in every image by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 44.84it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 34.94it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 103.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "\n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline                               \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Results from previous project\n",
    "\n",
    "TODO Must be deleted later\n",
    "\n",
    "1. The first extension experiment was with an exact copy of the previous ResNet architecture, just using the InceptionV3 bottleneck network upfront. This resulted in a test accuracy of: 82.7751%, i.e. worse than the Resnet50. The optimum result was already reached after 8 epochs, meaning that the architecture again did serious overfitting. In follow up experiments, this accuracy changed sometimes. One result was 80.3828%.\n",
    "\n",
    "2. The second extension experiment was changing the network architecture. I tried, not to use the GlobalAveragePooling layer, but instead flatten the data and then connect another dense layer. Although the number of parameters were not so high (around 500,000), this model ran into the problem of resource allocation and could not be solved.\n",
    "\n",
    "3. The third experiment was keeping the GlobalAveragePooling, but add another dense layer with dropouts. This resulted in an accuracy of 80.8612%. Again worse than before. \n",
    "\n",
    "4. I tested the XCeption network with a top network using two LeakyReLus and a fully connected layer with 512 nodes. This resulted in an accuracy of 84.0909%, which is comparable to the ResNet50 performance, but involves a much more complicated network and longer training times. As can be seen in the figures, this network reached its accurcy peak for validation quite early and overfitted afterwards.\n",
    "\n",
    "TODO: Playing around with batch size and optimizer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 9. Step Data Augmentation with Finetuning\n",
    "\n",
    "As mentioned above I had a look at this tutorial [Keras](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html). However, it was not possible for me to build the network based on this information.\n",
    "So, I did a research on the Slack channels and found the excellent notebook and app of [Jay Madhava](https://github.com/madhavajay/nd889/blob/master/2_deep_learning/1_dog_breed_classifier/dog_app.ipynb).\n",
    "Most parts of the following code are taken from there, but with my own modifications and experiments to learn the transfer and fine tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 81.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# InceptionV3 uses 299 x 299 images instead of the 224 x 224 above\n",
    "# So we need to generate another set of input tensors.\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from tqdm import tqdm\n",
    "\n",
    "def paths_to_inception_tensor(img_paths, width=299, height=299):\n",
    "    list_of_tensors = [preprocess_input(path_to_tensor(img_path, width, height)) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "inception_test_tensors = paths_to_inception_tensor(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77 images belonging to 4 classes.\n",
      "Found 7 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# TODO: Need to align with directories at the top!\n",
    "\n",
    "img_width, img_height = 299, 299\n",
    "batch_size = 8\n",
    "num_classes = 4\n",
    "train_dir = 'data/train'\n",
    "valid_dir = 'data/valid'\n",
    "\n",
    "# Data augmentation basically in the same way it was introduced with the cifar-10 dataset\n",
    "# Here we also use shear and zoom as the images are larger.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Same operation on the validation set\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, None, None, 32 864                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, None, None, 32 96                                           \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, None, None, 32 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, None, None, 32 9216                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, None, None, 32 96                                           \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, None, None, 32 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, None, None, 64 18432                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, None, None, 80 5120                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, None, None, 80 240                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, None, None, 80 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, None, None, 19 138240                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, None, None, 64 12288                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, None, None, 48 9216                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, None, None, 96 55296                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, None, None, 48 144                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, None, None, 96 288                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, None, None, 48 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, None, None, 96 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, None, None, 64 12288                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, None, None, 64 76800                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, None, None, 96 82944                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, None, None, 32 6144                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, None, None, 96 288                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, None, None, 32 96                                           \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_57 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, None, None, 96 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, None, None, 32 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, None, None, 25 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, None, None, 64 16384                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, None, None, 48 12288                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, None, None, 96 55296                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, None, None, 48 144                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, None, None, 96 288                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, None, None, 48 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, None, None, 96 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePool (None, None, None, 25 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, None, None, 64 16384                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, None, None, 64 76800                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, None, None, 96 82944                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, None, None, 64 16384                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, None, None, 96 288                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, None, None, 96 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, None, None, 28 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, None, None, 64 18432                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, None, None, 48 13824                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, None, None, 96 55296                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, None, None, 48 144                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, None, None, 96 288                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, None, None, 48 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, None, None, 96 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePool (None, None, None, 28 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, None, None, 64 18432                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, None, None, 64 76800                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, None, None, 96 82944                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, None, None, 64 18432                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, None, None, 96 288                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, None, None, 96 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, None, None, 28 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, None, None, 64 18432                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, None, None, 64 192                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, None, None, 64 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, None, None, 96 55296                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, None, None, 96 288                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_78 (Activation)       (None, None, None, 96 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, None, None, 38 995328                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, None, None, 96 82944                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, None, None, 96 288                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_79 (Activation)       (None, None, None, 96 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, None, None, 28 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, None, None, 12 98304                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, None, None, 12 384                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_84 (Activation)       (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, None, None, 12 114688                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, None, None, 12 384                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_85 (Activation)       (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, None, None, 12 98304                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, None, None, 12 114688                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, None, None, 12 384                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, None, None, 12 384                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_81 (Activation)       (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, None, None, 12 114688                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, None, None, 12 114688                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, None, None, 12 384                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, None, None, 12 384                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePool (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, None, None, 19 172032                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, None, None, 19 172032                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_80 (Activation)       (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, None, None, 16 122880                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, None, None, 16 179200                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, None, None, 16 122880                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, None, None, 16 179200                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, None, None, 16 179200                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, None, None, 16 179200                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePool (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, None, None, 19 215040                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, None, None, 19 215040                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, None, None, 16 122880                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, None, None, 16 179200                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_105 (Activation)      (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, None, None, 16 122880                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, None, None, 16 179200                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_106 (Activation)      (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, None, None, 16 179200                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, None, None, 16 179200                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (None, None, None, 16 480                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_107 (Activation)      (None, None, None, 16 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePool (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, None, None, 19 215040                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, None, None, 19 215040                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_108 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_109 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)               (None, None, None, 19 258048                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)               (None, None, None, 19 258048                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_111 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_116 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)               (None, None, None, 19 258048                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)               (None, None, None, 19 258048                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_112 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_117 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePool (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)               (None, None, None, 19 258048                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)               (None, None, None, 19 258048                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_110 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_113 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_118 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_119 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_122 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)               (None, None, None, 19 258048                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)               (None, None, None, 19 147456                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, None, None, 19 258048                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_120 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)               (None, None, None, 32 552960                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, None, None, 19 331776                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNor (None, None, None, 32 960                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_121 (Activation)      (None, None, None, 32 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)               (None, None, None, 44 573440                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, None, None, 44 1344                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, None, None, 44 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, None, None, 38 491520                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)               (None, None, None, 38 1548288                                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)               (None, None, None, 38 442368                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)               (None, None, None, 38 442368                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)               (None, None, None, 38 442368                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)               (None, None, None, 38 442368                                       \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePool (None, None, None, 12 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, None, None, 32 409600                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)               (None, None, None, 19 245760                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNor (None, None, None, 32 960                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, None, None, 32 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, None, None, 20 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, None, None, 44 917504                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, None, None, 44 1344                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, None, None, 44 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, None, None, 38 786432                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, None, None, 38 1548288                                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, None, None, 38 442368                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, None, None, 38 442368                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, None, None, 38 442368                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, None, None, 38 442368                                       \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePool (None, None, None, 20 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, None, None, 32 655360                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, None, None, 38 1152                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)               (None, None, None, 19 393216                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNor (None, None, None, 32 960                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, None, None, 38 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, None, None, 19 576                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, None, None, 32 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, None, None, 76 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, None, None, 19 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, None, None, 20 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glob (None, 2048)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 4)             8196                                         \n",
      "====================================================================================================\n",
      "Total params: 21,810,980.0\n",
      "Trainable params: 8,196.0\n",
      "Non-trainable params: 21,802,784.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Load Inception model without the top layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Freeze all layers so that the weights cannot be updated\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Construct our own model on top of Inception network\n",
    "# First use same architecture as above with just GlobalAveragePooling and a dense layer\n",
    "output = base_model.output\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "#output = Dense(512, activation='relu')(output)\n",
    "top_layers = Dense(4, activation='softmax')(output)\n",
    "\n",
    "finetune_model = Model(inputs=base_model.input, outputs=top_layers)\n",
    "\n",
    "finetune_model.summary()\n",
    "\n",
    "finetune_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 79 Validation Samples: 7 Batch Size: 8 Steps: 10\n",
      "Epoch 1/20\n",
      " 9/10 [==========================>...] - ETA: 4s - loss: 1.5610 - acc: 0.2361 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 0 took 44.79715171600401 seconds\n",
      "10/10 [==============================] - 44s - loss: 1.5562 - acc: 0.2133 - val_loss: 1.3146 - val_acc: 0.5714\n",
      "Epoch 2/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 1.2362 - acc: 0.4583 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 1 took 42.18389818799915 seconds\n",
      "10/10 [==============================] - 42s - loss: 1.3012 - acc: 0.4140 - val_loss: 1.2542 - val_acc: 0.4286\n",
      "Epoch 3/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 1.1796 - acc: 0.4583 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 2 took 43.32959362099791 seconds\n",
      "10/10 [==============================] - 43s - loss: 1.2177 - acc: 0.4333 - val_loss: 1.3319 - val_acc: 0.2857\n",
      "Epoch 4/20\n",
      " 9/10 [==========================>...] - ETA: 4s - loss: 1.0926 - acc: 0.5000 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 3 took 45.52982354300184 seconds\n",
      "10/10 [==============================] - 45s - loss: 1.1226 - acc: 0.4903 - val_loss: 1.1439 - val_acc: 0.2857\n",
      "Epoch 5/20\n",
      " 9/10 [==========================>...] - ETA: 4s - loss: 0.9477 - acc: 0.6389 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 4 took 47.90786224399926 seconds\n",
      "10/10 [==============================] - 47s - loss: 0.9792 - acc: 0.6158 - val_loss: 0.8530 - val_acc: 0.7143\n",
      "Epoch 6/20\n",
      " 9/10 [==========================>...] - ETA: 4s - loss: 0.7894 - acc: 0.7361 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 5 took 44.20708207700227 seconds\n",
      "10/10 [==============================] - 44s - loss: 0.7880 - acc: 0.7423 - val_loss: 1.0127 - val_acc: 0.4286\n",
      "Epoch 7/20\n",
      " 9/10 [==========================>...] - ETA: 4s - loss: 0.9209 - acc: 0.6667 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 6 took 50.01372416400409 seconds\n",
      "10/10 [==============================] - 50s - loss: 0.9147 - acc: 0.6602 - val_loss: 1.0538 - val_acc: 0.4286\n",
      "Epoch 8/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 0.7147 - acc: 0.8472 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 7 took 43.015152918997046 seconds\n",
      "10/10 [==============================] - 43s - loss: 0.7472 - acc: 0.8427 - val_loss: 1.0475 - val_acc: 0.4286\n",
      "Epoch 9/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 0.6526 - acc: 0.8472 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 8 took 42.41351996499725 seconds\n",
      "10/10 [==============================] - 42s - loss: 0.6343 - acc: 0.8427 - val_loss: 0.9645 - val_acc: 0.4286\n",
      "Epoch 10/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 0.6615 - acc: 0.7778 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 9 took 42.33440092700039 seconds\n",
      "10/10 [==============================] - 42s - loss: 0.6628 - acc: 0.7799 - val_loss: 1.2388 - val_acc: 0.4286\n",
      "Epoch 11/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 0.6145 - acc: 0.8194 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 10 took 42.103228200998274 seconds\n",
      "10/10 [==============================] - 42s - loss: 0.6200 - acc: 0.8176 - val_loss: 1.0913 - val_acc: 0.4286\n",
      "Epoch 12/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 0.5965 - acc: 0.8472 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 11 took 42.21784274200036 seconds\n",
      "10/10 [==============================] - 42s - loss: 0.6224 - acc: 0.8427 - val_loss: 0.9894 - val_acc: 0.4286\n",
      "Epoch 13/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 0.6583 - acc: 0.7778 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 12 took 42.625450254003226 seconds\n",
      "10/10 [==============================] - 42s - loss: 0.7222 - acc: 0.7218 - val_loss: 0.8051 - val_acc: 0.7143\n",
      "Epoch 14/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 0.6607 - acc: 0.7083 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 13 took 41.95275774599577 seconds\n",
      "10/10 [==============================] - 41s - loss: 0.6766 - acc: 0.6978 - val_loss: 0.8671 - val_acc: 0.7143\n",
      "Epoch 15/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 0.5986 - acc: 0.7917 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 14 took 42.18618003300071 seconds\n",
      "10/10 [==============================] - 42s - loss: 0.6263 - acc: 0.7537 - val_loss: 0.9534 - val_acc: 0.5714\n",
      "Epoch 16/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 0.5264 - acc: 0.8333 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 15 took 42.238616606002324 seconds\n",
      "10/10 [==============================] - 42s - loss: 0.5163 - acc: 0.8495 - val_loss: 1.0647 - val_acc: 0.5714\n",
      "Epoch 17/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 0.5674 - acc: 0.8472 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 16 took 44.31644484700519 seconds\n",
      "10/10 [==============================] - 44s - loss: 0.6429 - acc: 0.7652 - val_loss: 0.8311 - val_acc: 0.7143\n",
      "Epoch 18/20\n",
      " 9/10 [==========================>...] - ETA: 4s - loss: 0.5276 - acc: 0.8333 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 17 took 44.20057079200342 seconds\n",
      "10/10 [==============================] - 44s - loss: 0.5235 - acc: 0.8301 - val_loss: 1.0277 - val_acc: 0.5714\n",
      "Epoch 19/20\n",
      " 9/10 [==========================>...] - ETA: 4s - loss: 0.4932 - acc: 0.8472 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 18 took 44.72556943800009 seconds\n",
      "10/10 [==============================] - 44s - loss: 0.4813 - acc: 0.8620 - val_loss: 0.8631 - val_acc: 0.4286\n",
      "Epoch 20/20\n",
      " 9/10 [==========================>...] - ETA: 3s - loss: 0.4985 - acc: 0.8333 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 19 took 42.64282351500151 seconds\n",
      "10/10 [==============================] - 42s - loss: 0.4975 - acc: 0.8301 - val_loss: 0.7067 - val_acc: 0.7143\n",
      "Training took 875.0162239900019 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1364e7940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111e9a3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = math.ceil(train_tensors.shape[0]/batch_size)\n",
    "validation_steps = math.ceil(valid_tensors.shape[0]/batch_size)\n",
    "print('Training Samples: {} Validation Samples: {} Batch Size: {} Steps: {}'.format(\n",
    "      train_tensors.shape[0], valid_tensors.shape[0], batch_size, steps))\n",
    "\n",
    "epochs = 20\n",
    "epochtimer = EpochTimer()\n",
    "\n",
    "# TODO: Continuously save best model!\n",
    "\n",
    "hist = finetune_model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[epochtimer])\n",
    "\n",
    "show_history_graph(hist)\n",
    "\n",
    "top_model_file = 'saved_models/weights.best.{}.hdf5'.format('inceptionv3_top')\n",
    "finetune_model.save(top_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 57.1429%\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.argmax(finetune_model.predict(np.expand_dims(feature, axis=0))) for feature in inception_test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display some of the result images with correct or incorrect classification\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "for i, idx in enumerate(np.random.choice(test_tensors.shape[0], size=6, replace=False)):\n",
    "    ax = fig.add_subplot(2, 3, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(test_tensors[idx]))\n",
    "    true_idx = np.argmax(test_targets[idx])\n",
    "    pred_idx = predictions[idx]\n",
    "    ax.set_title(\"{}\\n({})\".format(burn_classes[pred_idx], burn_classes[true_idx]),\n",
    "                                  color=(\"green\" if pred_idx == true_idx else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Observations\n",
    "\n",
    "Looking at the training curves, the whole system definitely works and it is worth to continue this path further.\n",
    "It is quite clear, that the dataset at this stage is definitely way too small with just 7 samples in the validation and test set. The numbers for accuracy don't really mean anything.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning the whole network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# NB_IV3_LAYERS corresponds to the top 2 inception blocks in the inceptionv3 architecture\n",
    "# Those should be finetuned.\n",
    "NB_IV3_LAYERS_TO_FREEZE = 172\n",
    "for layer in finetune_model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "    layer.trainable = False\n",
    "for layer in finetune_model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "finetune_model.summary()\n",
    "\n",
    "# Use a slow stable learning method to prevent introducing bad noise into the lower layers\n",
    "finetune_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "steps = math.ceil(train_tensors.shape[0]/batch_size)\n",
    "validation_steps = math.ceil(valid_tensors.shape[0]/batch_size)\n",
    "print('Training Samples: {} Validation Samples: {} Batch Size: {} Steps: {}'.format(\n",
    "      train_tensors.shape[0], valid_tensors.shape[0], batch_size, steps))\n",
    "\n",
    "epochs = 20\n",
    "epochtimer = EpochTimer()\n",
    "\n",
    "hist = finetune_model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[epochtimer])\n",
    "\n",
    "show_history_graph(hist)\n",
    "\n",
    "finetune_model_file = 'saved_models/weights.best.{}.hdf5'.format('inceptionv3_finetune')\n",
    "finetune_model.save(finetune_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = [np.argmax(finetune_model.predict(np.expand_dims(feature, axis=0))) for feature in inception_test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "finetune_model_file = 'saved_models/weights.best.{}.hdf5'.format('inceptionv3_finetune')\n",
    "finetune_model.load_weights(finetune_model_file)\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as preprocess_inception_input\n",
    "\n",
    "def extract_InceptionV3(tensor):\n",
    "    return InceptionV3(weights='imagenet', include_top=False).predict(preprocess_inception_input(tensor))\n",
    "\n",
    "### Function that takes a path to an image as input\n",
    "### and returns the burn classification that is predicted by the finetuned model.\n",
    "def burn_classifier(img_path, selected_model, bottleneck=True, img_width=223, img_height=223):\n",
    "    tensor = path_to_tensor(img_path, img_width, img_height)\n",
    "    tensor = preprocess_inception_input(tensor)\n",
    "\n",
    "    predictions = selected_model.predict(tensor)\n",
    "    y_hat = np.argmax(predictions)\n",
    "    return dog_names[y_hat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Results\n",
    "\n",
    "With data augmentation and only training the top layers:\n",
    "TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# History graphs for the training of the top layers:\n",
    "show_history_graph(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# History graphs for the fine tuning of the \n",
    "# NB_IV3_LAYERS which correspond to the top 2 inception blocks in the inceptionv3 architecture\n",
    "show_history_graph(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
